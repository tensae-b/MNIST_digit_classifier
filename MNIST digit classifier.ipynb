{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e330b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b1bc563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce92bfe",
   "metadata": {},
   "source": [
    "<h1> Loading minst dataset </h1>\n",
    "\n",
    "importing the mnist data set from keras and splitting it in to test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3e251512",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,Y_train),(X_test,Y_test)= keras.datasets.mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4a524d",
   "metadata": {},
   "source": [
    "<h1> visualizing the data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1cb26d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "94d5bcd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2e71390e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c0cf6b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e28371cf88>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2af83e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a7f255b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "45a6b8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc71b60",
   "metadata": {},
   "source": [
    "changing the data to 0-1  range for better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a75a5b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= X_train/255\n",
    "X_test = X_test/255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc494bd",
   "metadata": {},
   "source": [
    "reshaping (flattening ) the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "cc614d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flattend= X_train.reshape(len(X_train),28*28)\n",
    "X_test_flattend= X_test.reshape(len(X_test),28*28)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1bf54d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a46e81dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_flattend.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d8cea649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "       0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117647, 0.36862745, 0.60392157,\n",
       "       0.66666667, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235294, 0.6745098 , 0.99215686, 0.94901961,\n",
       "       0.76470588, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215686, 0.93333333,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.98431373, 0.36470588,\n",
       "       0.32156863, 0.32156863, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882353, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.71372549,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31372549, 0.61176471, 0.41960784, 0.99215686, 0.99215686,\n",
       "       0.80392157, 0.04313725, 0.        , 0.16862745, 0.60392157,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509804,\n",
       "       0.99215686, 0.74509804, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313725, 0.74509804, 0.99215686,\n",
       "       0.2745098 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.1372549 , 0.94509804, 0.88235294, 0.62745098,\n",
       "       0.42352941, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764706, 0.94117647, 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "       0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.36470588,\n",
       "       0.98823529, 0.99215686, 0.73333333, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.97647059, 0.99215686,\n",
       "       0.97647059, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980392,\n",
       "       0.71764706, 0.99215686, 0.99215686, 0.81176471, 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.58039216, 0.89803922, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.71372549, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882353, 0.83529412, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.31764706,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058824, 0.85882353,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.76470588,\n",
       "       0.31372549, 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568627, 0.6745098 ,\n",
       "       0.88627451, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156863, 0.04313725, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333333, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137255, 0.52941176, 0.51764706, 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattend[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d2c7d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3753d40b",
   "metadata": {},
   "source": [
    "<h1> Functions to train the model </h1>\n",
    "<h3>first, model train with no hidden layer<h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "5ba1d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training with no hidden layers\n",
    "def no_hidden_layer(X_train_flattend,Y_train,epoch):\n",
    "    model= keras.Sequential([\n",
    "        keras.layers.Dense(10,input_shape=(784,),activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy']\n",
    "\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_flattend,Y_train,validation_data=(X_test, Y_test),epochs=epoch )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700ea8cc",
   "metadata": {},
   "source": [
    "<h3>second, model train with one hidden layer</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "17436c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training with one hidden layer\n",
    "def one_hidden_layer(X_train_flattend,Y_train,epoch):\n",
    "    model= keras.Sequential([\n",
    "        keras.layers.Dense(100,input_shape=(784,),activation='relu'),\n",
    "        keras.layers.Dense(10,activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        \n",
    "      optimizer='adam',\n",
    "      loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=['accuracy']\n",
    "    )\n",
    "   \n",
    "    model.fit(X_train_flattend,Y_train,validation_data=(X_test, Y_test),epochs=epoch)\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f1e541",
   "metadata": {},
   "source": [
    "<h1> Training the model with no hidden layers </h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ba5ea0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.4902 - acc: 0.8744 - val_loss: 0.3077 - val_acc: 0.9167\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3054 - acc: 0.9162 - val_loss: 0.2860 - val_acc: 0.9187\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2852 - acc: 0.9206 - val_loss: 0.2774 - val_acc: 0.9237\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2746 - acc: 0.9243 - val_loss: 0.2687 - val_acc: 0.9258\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2676 - acc: 0.9265 - val_loss: 0.2646 - val_acc: 0.9251\n"
     ]
    }
   ],
   "source": [
    "model=no_hidden_layer(X_train_flattend,Y_train,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53010223",
   "metadata": {},
   "source": [
    "<h1> Testing the model with no hidden layer </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e123babf",
   "metadata": {},
   "source": [
    "the model with no hidden layer gives an accuracy of 92 percent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0540618e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 18us/sample - loss: 0.2646 - acc: 0.9251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26463529813587666, 0.9251]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_flattend,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "cf97492f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5255809e-04, 1.3113022e-06, 3.2843766e-01, 1.3026595e-04,\n",
       "       0.0000000e+00, 1.7699301e-03, 1.3635755e-03, 0.0000000e+00,\n",
       "       6.3776970e-05, 0.0000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted=model.predict(X_test_flattend)\n",
    "y_predicted[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6814d20",
   "metadata": {},
   "source": [
    "since the above cell out gave us the likeliness of all the 10 digits, we will out put the maximum likeliness using argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1d22d7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_predicted[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "f5163eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 2, 1, 0, 4]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_labels=[np.argmax(i) for i in y_predicted]\n",
    "y_predicted_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1c01517d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4], dtype=uint8)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32e811b",
   "metadata": {},
   "source": [
    "<h1> training with one hidden layer </h1>\n",
    "\n",
    "<p>adding on hidden layer for better accuracy </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9ea5dbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.2787 - acc: 0.9201 - val_loss: 0.1481 - val_acc: 0.9562\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.1267 - acc: 0.9628 - val_loss: 0.1050 - val_acc: 0.9685\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0892 - acc: 0.9731 - val_loss: 0.0887 - val_acc: 0.9732\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0687 - acc: 0.9793 - val_loss: 0.0843 - val_acc: 0.9746\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0545 - acc: 0.9831 - val_loss: 0.0849 - val_acc: 0.9736\n"
     ]
    }
   ],
   "source": [
    "model1=one_hidden_layer(X_train_flattend,Y_train,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73eee78",
   "metadata": {},
   "source": [
    "<h1> Testing the model with one hidden layer </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec968df9",
   "metadata": {},
   "source": [
    "the model with one hidden layer gives an accuracy of 97 percent with is 5 percent more than the model with no hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "424f2f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.0849 - acc: 0.9736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0848653153634863, 0.9736]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test_flattend,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101e655b",
   "metadata": {},
   "source": [
    " we will out put the maximum likeliness from all the 10 digits using argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "282a3d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted=model1.predict(X_test_flattend)\n",
    "np.argmax(y_predicted[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "7cf4b126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 2, 1, 0, 4]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_labels1=[np.argmax(i) for i in y_predicted]\n",
    "y_predicted_labels1[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
